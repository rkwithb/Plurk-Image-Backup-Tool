import os
import re
import json
import requests
from datetime import datetime
from pathlib import Path

import sys
import io

# ==========================================
# I/O å¼·å¥æ€§åˆå§‹åŒ– (Robustness Initialization)
# ==========================================
if sys.platform == "win32":
    if sys.stdout is not None and hasattr(sys.stdout, 'buffer'):
        try:
            # å¼·åˆ¶ä½¿ç”¨ UTF-8 ä¸¦é–‹å•Ÿè¡Œç·©è¡ï¼Œé˜²æ­¢ Windows ç’°å¢ƒç·¨ç¢¼å´©æ½°
            sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', line_buffering=True)
        except Exception:
            pass
    elif sys.stdout is None:
        # é˜²æ­¢ --windowed æ¨¡å¼æˆ–ç„¡æ§åˆ¶å°ç’°å¢ƒä¸‹ print å´©æ½°
        sys.stdout = open(os.devnull, 'w')

def safe_input(prompt, default="n"):
    """
    å¼·å¥çš„è¼¸å…¥å‡½å¼ï¼š
    1. åµæ¸¬æ˜¯å¦ç‚º TTY (äº’å‹•å¼çµ‚ç«¯æ©Ÿ)ï¼Œè‹¥éäº’å‹•ç’°å¢ƒå‰‡ç›´æ¥å›å‚³é è¨­å€¼ï¼ˆè§£æ±º GitHub Actions å ±éŒ¯ï¼‰ã€‚
    2. æ•æ‰ EOFError èˆ‡ OSErrorï¼Œé˜²æ­¢ç¨‹å¼åœ¨æ„å¤–ä¸­æ–·æ™‚å´©æ½°ã€‚
    """
    try:
        # æª¢æŸ¥æ¨™æº–è¼¸å…¥æ˜¯å¦é€£æ¥åˆ°çµ‚ç«¯æ©Ÿ
        if not sys.stdin or not sys.stdin.isatty():
            return default
        return input(prompt).lower()
    except (EOFError, OSError):
        return default

# å˜—è©¦åŒ¯å…¥ piexifï¼Œè®“åŠŸèƒ½è®Šæˆã€Œé¸é…ã€
try:
    import piexif
    PIEXIF_AVAILABLE = True
except ImportError:
    PIEXIF_AVAILABLE = False

# --- è¨­å®šå€ ---
OUTPUT_ROOT = Path("å™—æµªJSåœ–ç‰‡å‚™ä»½_ç²¾ç¢ºåˆ†é¡")
PLURKS_DIR = Path("data/plurks")
RESPONSES_DIR = Path("data/responses")

# æ­£è¦è¡¨ç¤ºå¼ï¼šæ’é™¤å®˜æ–¹è²¼åœ–ï¼ŒæŠ“å–ä¸€èˆ¬åœ–æª”
PLURK_EMOJI_PATTERN = re.compile(r'https://images\.plurk\.com/mx_')
GENERAL_IMAGE_PATTERN = re.compile(r'https?://[^\s"\'\\]+\.(?:jpg|png|gif|jpeg)', re.IGNORECASE)

def get_all_valid_images(text_content):
    """æ“·å–æœ‰æ•ˆåœ–ç‰‡é€£çµï¼Œæ’é™¤å®˜æ–¹è¡¨æƒ…èˆ‡ç³»çµ±åœ–"""
    if not text_content: return set()
    clean_text = text_content.replace('\\/', '/')
    all_urls = GENERAL_IMAGE_PATTERN.findall(clean_text)
    valid_urls = set()
    for url in all_urls:
        low_url = url.lower()
        if "emos.plurk.com" in low_url or "static.plurk.com" in low_url:
            continue
        if "images.plurk.com" in low_url and PLURK_EMOJI_PATTERN.search(url):
            continue
        valid_urls.add(url)
    return valid_urls

def write_exif_time(file_path, dt_obj):
    """åªæœ‰åœ¨æ™‚é–“ç©ºç™½æˆ–ä¸ä¸€è‡´æ™‚ï¼Œæ‰åŸ·è¡Œ EXIF è¦†å¯«"""
    if not PIEXIF_AVAILABLE or file_path.suffix.lower() not in ['.jpg', '.jpeg']:
        return False
    try:
        target_time_str = dt_obj.strftime("%Y:%m:%d %H:%M:%S")
        exif_dict = piexif.load(str(file_path))
        # å–å¾—æ‹æ”æ—¥æœŸæ¬„ä½ (DateTimeOriginal)
        current_time = exif_dict.get("Exif", {}).get(piexif.ExifIFD.DateTimeOriginal)
        current_time_str = current_time.decode('utf-8') if isinstance(current_time, bytes) else current_time


        # å¦‚æœå·²ç¶“æœ‰ä¸€è‡´çš„æ™‚é–“ï¼Œå°±è·³éä¸è™•ç†ï¼Œç¯€çœæ™‚é–“
        if current_time_str == target_time_str:
            return False

        print(f"  ğŸ•’ æ­£åœ¨æ›´æ–° EXIF æ™‚é–“æ¨™é ­: {file_path.name}")
        exif_dict["0th"][piexif.ImageIFD.DateTime] = target_time_str
        exif_dict["Exif"][piexif.ExifIFD.DateTimeOriginal] = target_time_str
        exif_dict["Exif"][piexif.ExifIFD.DateTimeDigitized] = target_time_str
        piexif.insert(piexif.dump(exif_dict), str(file_path))
        #print(f"ğŸ•’ è¦†å¯«/æ ¡æ­£ EXIF æ¨™é ­:",target_time_str,"/",str(file_path))

        return True
    except:
        # è‹¥åŸæª”æ ¼å¼ç‰¹æ®Šæˆ–ç„¡ EXIF å€å¡Šï¼Œå‰‡å¼·åˆ¶æ–°å»º
        try:
            exif_date = dt_obj.strftime("%Y:%m:%d %H:%M:%S")
            new_exif = {"0th": {piexif.ImageIFD.DateTime: exif_date},
                        "Exif": {piexif.ExifIFD.DateTimeOriginal: exif_date}}
            piexif.insert(piexif.dump(new_exif), str(file_path))
            return True
        except: return False

def download_image(url, target_folder, dt_obj, do_exif):
    """ä¸‹è¼‰é‚è¼¯ï¼šæ”¯æ´é¸æ“‡æ˜¯å¦è™•ç† EXIF"""
    file_name = url.split('/')[-1].split('?')[0]
    save_path = target_folder / file_name
    target_folder.mkdir(exist_ok=True, parents=True)

    if save_path.exists():
        updated = write_exif_time(save_path, dt_obj) if do_exif else False
        return False, True, updated

    try:
        res = requests.get(url, timeout=15)
        if res.status_code == 200 and len(res.content) > 5120:
            with open(save_path, "wb") as f:
                f.write(res.content)
            updated = write_exif_time(save_path, dt_obj) if do_exif else False
            return True, False, updated
    except: pass
    return False, False, False

def parse_js_content(file_path):
    """ç²¾ç¢ºè™•ç† BackupData æ ¼å¼"""
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            raw_text = f.read().strip()
            eq_index = raw_text.find('=')
            if eq_index == -1: return []
            json_part = raw_text[eq_index + 1:].strip()
            if json_part.endswith(';'): json_part = json_part[:-1].strip()
            return json.loads(json_part, strict=False)
    except: return []

def _process_folder(source_dir, label, do_exif):
    """æƒæ JS æª”æ¡ˆä¸¦è™•ç†åœ–æª”"""
    counts = {"dl": 0, "skip": 0, "exif": 0}
    if not source_dir.exists():
        print(f"âš ï¸ æ‰¾ä¸åˆ° {label} è³‡æ–™å¤¾ï¼Œç•¥éè™•ç†ã€‚")
        return counts

    for js_file in source_dir.glob("*.js"):
        items = parse_js_content(js_file)
        if not items: continue

        print(f"ğŸ“‚ [{label}] è™•ç†æª”æ¡ˆä¸­: {js_file.name}")
        for item in items:
            posted_date = item.get("posted", "")
            try:
                dt = datetime.strptime(posted_date, "%a, %d %b %Y %H:%M:%S GMT")
                # ç¶­æŒæŒ‰å¤©åˆ†é¡ (YYYY-MM-DD)
                date_folder = OUTPUT_ROOT / dt.strftime("%Y-%m-%d")
            except: continue

            content = (item.get("content", "") or "") + " " + (item.get("content_raw", "") or "")
            urls = get_all_valid_images(content)

            for url in urls:
                is_dl, is_exist, is_exif = download_image(url, date_folder, dt, do_exif)
                if is_dl: counts["dl"] += 1
                if is_exist: counts["skip"] += 1
                if is_exif: counts["exif"] += 1
    return counts

def main():
    print("ğŸš€ å™—æµª JS å‚™ä»½åœ–æª”æ•´ç†å·¥å…· (Flexible Version)")

    # EXIF é¸æ“‡é‚è¼¯
    # æå‡ Robustness: ä½¿ç”¨ safe_input ä»£æ›¿åŸç”Ÿ input
    do_exif = False
    if PIEXIF_AVAILABLE:
        choice = safe_input("ğŸ‘‰ æ˜¯å¦è¦æª¢æŸ¥ä¸¦è£œå¯«/è¦†è“‹åœ–æª”çš„ EXIF æ™‚é–“æ¨™é ­ï¼Ÿ(y/N): ")
        if choice == 'y':
            do_exif = True
    else:
        print("ğŸ’¡ æç¤ºï¼šç³»çµ±æœªå®‰è£ piexif æ¨¡çµ„ï¼Œå°‡æ”¹ç‚ºç´”ä¸‹è¼‰æ¨¡å¼ã€‚")

    OUTPUT_ROOT.mkdir(exist_ok=True)

    # åŸ·è¡Œä¸»å™—èˆ‡å›æ‡‰çš„è™•ç†
    p_stats = _process_folder(PLURKS_DIR, "ä¸»å™—", do_exif)
    r_stats = _process_folder(RESPONSES_DIR, "å›æ‡‰", do_exif)

    print("\n" + "="*40)
    print("âœ¨ å‚™ä»½æ•´ç†çµæœï¼š")
    print(f"ğŸ“¥ æ–°ä¸‹è¼‰åœ–ç‰‡: {p_stats['dl'] + r_stats['dl']} å¼µ")
    print(f"â­ï¸ ç•¥éå·²å­˜åœ¨åœ–æª”: {p_stats['skip'] + r_stats['skip']} å¼µ")
    if do_exif:
        print(f"ğŸ•’ è¦†å¯«/æ ¡æ­£ EXIF æ¨™é ­: {p_stats['exif'] + r_stats['exif']} å¼µ")
    print("="*40)

if __name__ == "__main__":
    main()